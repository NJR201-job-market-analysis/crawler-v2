# Cake 爬蟲系統

程式碼位於 https://github.com/NJR201-job-market-analysis/crawler/cake

一個基於 Celery 和 RabbitMQ 的分布式爬蟲系統，用於爬取 Cake 平台的職缺資訊。

## 📁 目錄結構

```
/root/job-crawler/cake/
├── setup.py                    # Python 包配置
├── Pipfile                     # Python 依賴管理
├── local.ini                   # 環境配置文件
├── genenv.py                   # 環境變數生成器
├── .env                        # 環境變數文件（自動生成）
├── crawler/                    # 爬蟲模組目錄
│   ├── __init__.py
│   ├── cake_config.py          # 配置管理
│   ├── cake_worker.py          # Celery Worker 配置
│   ├── cake_tasks.py           # Celery 任務定義
│   ├── cake_producer.py        # 任務生產者
│   ├── cake_crawler.py         # 核心爬蟲邏輯
│   └── main.py                 # 主程序入口
└── docker-compose.monitor.yml  # Docker 監控配置
```

## 🚀 快速開始

### 1. 環境準備

```bash
# 進入項目目錄
cd /job-crawler/cake

# 生成環境變數文件
ENV=DOCKER|DEV pipenv run python genenv.py

# 安裝依賴
pipenv install

# 構建 Docker 映像檔
docker build -f Dockerfile -t xxx/cake-crawler:0.0.0 .

# 推送到 Docker Hub
docker push xxx/cake-crawler:0.0.0

# 啟動 RabbitMQ、MySQL、Flower、PhpMyAdmin 容器
docker compose -f docker-compose.monitor.yml up -d

# 啟動 Cake 爬蟲 Worker
DOCKER_IMAGE_VERSION=0.0.0 docker compose -f docker-compose.app.yml up -d cake_worker_1

# 查看 Worker 日誌，確定正常啟動
docker logs cake_worker_1

# 啟動 Cake 任務生產者，確定有執行發送任務
DOCKER_IMAGE_VERSION=0.0.0 docker compose -f docker-compose.app.yml up -d cake_producer

# 查看任務發送狀況
docker logs cake_producer

# 如果都正常執行，等 Worker 跑完可訪問 localhost:8080 查看資料是否寫入
```

### 2. 關閉 Docker 服務

```bash
# 使用 Docker compose
docker compose -f docker-compose.monitor.yml down
docker compose -f docker-compose.app.yml down

# 查看容器狀態
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

### 3: 在終端機啟動 Worker、Producer

```bash
# 終端 1: 啟動 Worker
pipenv run celery -A crawler.cake_worker worker --loglevel=info

# 查看 Worker 狀態
pipenv run celery -A crawler.cake_worker status
ps aux | grep celery

# 終端 3: 執行 Producer
pipenv run python crawler.cake_producer

# 或是直接執行測試
pipenv run python crawler/main.py
```

### 監控任務執行

- **Worker 終端**: 查看任務執行日誌 docker logs cake_worker_1
- **Flower 界面**: 查看任務狀態和統計 (http://localhost:5555)
- **RabbitMQ 管理界面**: 查看隊列狀態 (http://localhost:15672)
- **MySQL 管理界面**: 查看資料庫狀態 (http://localhost:8080)

### 任務配置

```python
# cake_producer.py
crawl_cake_jobs.delay(
    category="software-developer",    # 職缺類別
    job_type="it_front-end-engineer", # 職位類型
    filename="cake_jobs.csv",         # 輸出文件名
)
```

## 程式碼架構

- **`cake_config.py`**: 環境變數管理，連接 RabbitMQ 和 MySQL
- **`local.ini`**: 多環境配置（DEV/DOCKER/PRODUCTION）
- **`genenv.py`**: 根據環境生成 `.env` 文件
- **`cake_worker.py`**: Celery 應用配置，連接 RabbitMQ
- **`cake_tasks.py`**: 定義爬蟲任務和測試任務
- **`cake_producer.py`**: 任務生產者，發送爬蟲任務、將資料寫入DB
- **`cake_crawler.py`**: 核心爬蟲邏輯，解析 Cake 網站
